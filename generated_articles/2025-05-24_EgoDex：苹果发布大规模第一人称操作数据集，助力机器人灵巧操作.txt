标题：EgoDex：苹果发布大规模第一人称操作数据集，助力机器人灵巧操作


近年来，人工智能领域在自然语言和图像识别方面取得了显著进展，这主要归功于大规模数据集的推动。然而，在机器人灵巧操作领域，数据匮乏一直是个难题。为了解决这个问题，苹果公司推出了EgoDex，这是一个迄今为止最大、最多样化的灵巧人手操作数据集，旨在推动机器人、计算机视觉和基础模型的发展。

EgoDex数据集的核心在于其大规模的第一人称视角视频，并配有精确的3D手部姿态标注。研究人员利用Apple Vision Pro收集了829小时的视频，包含9000万帧图像和超过33万个任务演示，涵盖194种不同的桌面操作任务，从系鞋带到叠衣服，应有尽有。与现有数据集相比，EgoDex不仅规模更大，而且具有独特的优势。

EgoDex的数据收集方式具有被动可扩展性，无需像机器人遥操作那样耗费大量人力物力。此外，EgoDex以人手作为通用的操作载体，避免了对特定机器人硬件平台的依赖。数据集包含30FPS的1080p第一人称视角视频，捕捉了人手操作时的真实场景。更重要的是，EgoDex提供了高精度、高细节的3D姿态信息，包括头部、手臂、手腕以及每根手指的25个关节，这是现有互联网视频和Ego4D等数据集所不具备的。

研究人员在EgoDex数据集上训练并评估了模仿学习策略，用于手部轨迹预测。他们引入了新的评估指标和基准，旨在衡量该领域的研究进展。实验结果表明，编码器-解码器架构优于仅解码器架构，不同的策略表示在不同的设置下表现各异，视觉目标条件化能够显著提高性能，并且模型性能随着数据集规模的扩大而提升。

EgoDex数据集的发布，为机器人操作、计算机视觉、增强现实、辅助假肢和人机交互等领域带来了广阔的应用前景。例如，通过模仿学习，可以训练机器人完成各种复杂的灵巧操作任务。此外，EgoDex还可以用于训练视频生成和世界模型，从而使人工智能系统能够更好地理解和预测人类的行为。

标签：#机器人操作 #第一人称视角 #数据集 #模仿学习 #人工智能