标题：无需输出！新型AI自评估技术揭秘：像人类一样思考


大型语言模型（LLMs）的能力日益强大，但其输出结果有时并不稳定，可能产生错误甚至有害的回答。为了提高LLM的可靠性，让AI能够自我评估答案的正确性至关重要。本文将解读一项最新的研究，该研究提出了一种名为“潜在空间链式嵌入”（Chain-of-Embedding，CoE）的新方法，使LLM能够在不依赖输出文本的情况下进行自我评估，就像人类通过思考路径来判断答案是否正确一样。

**研究动机与背景**

传统的LLM自评估方法主要依赖于输出结果，例如让LLM对自己的回答给出置信度评分，或者通过扰动输入生成多个答案并比较它们的一致性。然而，这些方法忽略了LLM内部的“思考”过程。最近的研究表明，LLM的潜在空间蕴藏着大量未被利用的信息，这些信息能够反映答案的正确性。但是，以往利用潜在空间进行自评估的方法通常需要标注数据来训练分类器，这与“无标注”的目标相悖。因此，如何仅利用LLM的内部状态来评估答案的正确性，成为了一个具有挑战性但极具价值的问题。

**方法与技术亮点**

这项研究的核心在于模拟人类的思考过程。认知理论认为，人类的思考是由直觉思维（系统1）和审慎思维（系统2）共同完成的。正确的思考往往会激活系统2，产生更审慎的思考路径，而错误的思考则容易受到系统1的影响，导致更快速和直接的思考路径。研究人员将这一思想迁移到LLM上，提出了CoE的概念。CoE是指LLM在推理过程中产生的所有隐藏状态的序列，可以将其视为LLM的潜在思考路径。研究人员发现，当LLM回答正确和错误时，它们的CoE特征存在差异。具体来说，研究人员定义了CoE的两个关键特征：幅度（magnitude）和角度（angle）。幅度反映了思考路径的曲折程度，角度则反映了语义建模的稳定性。研究表明，正确答案的CoE幅度更大，角度更小，这意味着LLM在给出正确答案时，思考路径更曲折，语义建模更稳定。

**主要发现与成果**

基于CoE特征，研究人员提出了两种自评估指标：CoE-R（实数空间组合）和CoE-C（复数空间组合）。CoE-R直接将幅度和角度进行数值加权组合，而CoE-C则将幅度和角度视为复数的模和辐角，在复数空间中进行组合。实验结果表明，这两种方法在数学、推理、知识和理解四个领域都取得了显著的效果，优于现有的自评估方法。更重要的是，CoE方法无需任何训练，计算成本极低，可以在大规模场景中实现实时反馈。

**意义与应用前景**

这项研究为LLM的自评估提供了一种全新的思路，它不依赖于输出文本，而是深入挖掘LLM内部的思考过程。CoE方法具有无需标注数据、计算成本低、可解释性强等优点，有望在LLM的部署和应用中发挥重要作用。例如，可以利用CoE方法对LLM的回答进行实时监控，及时发现并纠正错误，从而提高LLM的可靠性和安全性。此外，CoE方法还可以帮助我们更深入地理解LLM的内部机制，为未来的AI研究提供新的启示。

标签：#大型语言模型 #自评估 #链式嵌入 #人工智能 #科研进展