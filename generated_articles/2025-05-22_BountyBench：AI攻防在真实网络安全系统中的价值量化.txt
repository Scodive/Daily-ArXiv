标题：BountyBench：AI攻防在真实网络安全系统中的价值量化


在快速发展的网络安全领域，人工智能（AI）正扮演着日益重要的角色。为了更准确地评估AI在网络攻防中的能力和潜在影响，一项新的研究提出了BountyBench框架，旨在量化AI在真实网络安全系统中的经济价值。这项研究通过模拟真实世界的漏洞生命周期，为AI在网络安全领域的应用提供了更全面的评估视角。

**研究动机与背景**

现有的网络安全基准测试往往存在局限性，例如，侧重于孤立的代码片段漏洞检测或简单的攻防对抗，难以捕捉真实世界系统的复杂性和演进性。此外，传统的“成功条件”评估方法，如捕获Flag或服务器健康检查，只能反映攻击是否成功，而无法揭示导致成功的具体漏洞。BountyBench应运而生，旨在弥补这些不足，提供一个更贴近实际、更全面的评估框架。

**方法与技术亮点**

BountyBench的核心在于模拟漏洞从发现到修复的完整生命周期，并将其与实际的经济奖励（bug bounty）挂钩。该框架包含以下关键要素：

*   **真实世界系统**：选取25个具有复杂代码库的真实系统，涵盖9项OWASP Top 10风险。
*   **漏洞生命周期任务**：定义三种任务类型：`Detect`（检测新漏洞）、`Exploit`（利用特定漏洞）和`Patch`（修复特定漏洞），全面模拟漏洞的生命周期。
*   **Detect成功指标**：针对`Detect`任务，研究者提出了一种新的成功指标，该指标具有通用性，适用于各种漏洞类型，并提供本地化评估。该指标验证AI生成的攻击是否在未修补的系统上成功，而在修补后的系统上失败。
*   **任务难度调节**：通过提供不同程度的信息来调节任务难度，从识别零日漏洞到利用特定漏洞，实现难度平滑过渡。
*   **经济价值量化**：将漏洞与实际的bug bounty奖励关联，量化AI在网络安全攻防中的经济影响。

**主要发现与成果**

研究者利用BountyBench评估了5种AI Agent在网络安全任务中的表现，包括Claude Code、OpenAI Codex CLI以及基于GPT-4.1、Gemini 2.5 Pro Preview和Claude 3.7 Sonnet Thinking的自定义Agent。结果显示：

*   在`Detect`任务中，Claude Code和自定义Agent（Claude 3.7 Sonnet Thinking）表现突出，成功率均为5%，分别对应1350美元和1025美元的潜在奖励。OpenAI Codex CLI在`Detect`任务中成功率同样为5%，但对应2400美元的潜在奖励。
*   在`Exploit`任务中，自定义Agent（Claude 3.7 Sonnet Thinking）表现最佳，成功率为67.5%。
*   在`Patch`任务中，OpenAI Codex CLI和Claude Code表现出色，成功率分别为90%和87.5%，对应14422美元和13862美元的潜在奖励。
*   OpenAI Codex CLI和Claude Code更擅长防御，`Patch`成功率高于`Exploit`成功率；而自定义Agent在攻防之间相对平衡。
*   信息是调节任务难度的有效手段，Agent的表现随着信息的增加而提升。

**意义与应用前景**

BountyBench的提出为AI在网络安全领域的评估提供了一个更全面、更贴近实际的框架。通过量化AI在攻防中的经济价值，BountyBench有助于：

*   更准确地评估AI在网络安全领域的风险和收益。
*   指导网络安全策略的制定和资源分配。
*   促进AI在网络安全领域的创新和发展。

研究者计划未来将持续更新和改进BountyBench，增加更多系统、Agent和任务，并探索自动化任务和系统创建的方法，以提高评估的效率和准确性。

标签：#人工智能 #网络安全 #漏洞挖掘 #AI攻防 #经济价值量化