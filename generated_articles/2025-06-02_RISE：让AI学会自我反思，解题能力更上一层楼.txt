标题：RISE：让AI学会自我反思，解题能力更上一层楼


大型语言模型（LLMs）在复杂推理任务中展现出巨大潜力，而利用可验证奖励的强化学习（RLVR）是进一步提升这些能力的关键策略。然而，一个普遍存在的问题是“表面自反思”，即模型无法可靠地验证自己的输出。本文解读的论文提出了一种名为RISE（Reinforcing Reasoning with Self-Verification）的全新在线强化学习框架，旨在解决这一问题。

**研究动机与背景**：
当前，即使采用基于结果的强化学习，模型也可能学会生成正确的答案，而没有真正理解底层的推理过程或具备强大的自我评估能力。这会导致“表面自反思”，模型难以可靠地识别自身推理中的缺陷并验证输出的正确性。

**方法与技术亮点**：
RISE的核心机制是利用来自结果验证器的可验证奖励，为解决方案生成和自我验证任务提供即时反馈。在每次迭代中，模型生成解决方案，然后批判性地评估其自身生成的解决方案，这两个过程都对策略更新做出贡献。具体来说，RISE框架在每个训练迭代期间，模型首先为一批问题生成解决方案。随后，使用这些在线生成的解决方案和原始问题，通过预定义的模板构建验证问题，提示模型批判性地评估其自身的解决方案并给出评分。用于评估问题解决方案的相同结果验证器也为验证任务提供ground-truth监督，基于预测的验证分数和ground-truth解决方案分数之间的精确匹配。

**主要发现与成果**：
论文在各种数学推理基准上进行了大量实验，结果表明RISE能够持续提高模型的问题解决准确率，同时培养强大的自我验证技能。分析表明，在线验证具有优势，增加验证计算量也大有裨益。此外，RISE模型在推理过程中表现出更频繁和准确的自我验证行为。与仅包含问题解决监督的Zero-RL基线相比，RISE模型在所有模型尺寸上始终优于其Zero-RL对应模型，在具有挑战性的数学基准测试中，验证准确率提高了2.8倍。

**意义与应用前景**：
RISE的优势在于它是一种灵活有效的途径，可以开发出更强大、更具自我意识的推理器。通过同时训练LLM来提高其问题解决能力和自我验证能力，RISE为构建更可靠、更值得信赖的AI系统奠定了基础。未来，RISE有望应用于代码生成、物理推理等其他领域，并与其他技术（如检索增强生成）相结合，进一步提升AI的推理能力。

标签：#人工智能 #强化学习 #自我验证 #数学推理 #语言模型