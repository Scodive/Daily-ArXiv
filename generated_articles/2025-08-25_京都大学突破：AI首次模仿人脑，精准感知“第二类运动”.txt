标题：京都大学突破：AI首次模仿人脑，精准感知“第二类运动”


这项由京都大学研究团队发表的论文，名为《Machine Learning Modeling for Multi-order Human Visual Motion Processing》，为人工智能在理解视觉运动方面带来了重大进展。尽管当前计算机视觉（CV）模型在精确计算光流方面表现出色，但它们在模仿人脑处理视觉信息的方式上仍存在显著差距，尤其是在感知“第二类运动”方面。这项研究旨在弥合这一差距，创造出既能准确计算运动，又能像人一样理解复杂视觉场景的AI。

**研究动机与背景**

人类视觉系统能够感知多种类型的运动，其中“第一类运动”主要基于亮度变化，而“第二类运动”则依赖于对比度、纹理等高阶特征的变化。现有的大多数计算机视觉模型，由于其对亮度守恒定律的依赖，难以捕捉这种第二类运动。这限制了它们在复杂自然场景中的应用，例如在识别具有反光或透明材质的物体时。研究人员希望构建一个能够同时处理这两种运动的AI模型，以更全面地模拟人类的视觉感知能力。

**方法与技术亮点**

该研究的核心在于其仿生学模型设计，它借鉴了灵长类动物视觉皮层V1到MT的处理通路。模型采用了两阶段的处理流程：

第一阶段（模拟V1）：构建了一个可训练的“运动能量传感器”库。与传统的固定滤波器不同，这些传感器的参数（如对速度和方向的偏好）可以学习，使其能更灵活地适应自然场景中的光流计算。特别之处在于，研究者引入了一个“双通道”设计：一个通道处理第一类（亮度）运动，另一个通道则利用3D卷积神经网络（CNN）来提取非线性的时空特征，为感知第二类运动做准备。

第二阶段（模拟MT）：引入了一个“循环图网络”来整合第一阶段提取的局部运动信息。这个网络将图像中的每个空间位置视为一个节点，并通过自注意力机制建立连接，形成一个“运动图”。这种图结构允许模型进行灵活的全局运动整合，有效解决“孔径问题”（即局部信息不足以判断整体运动方向的问题）。此外，这种图的连接特性还使得模型在无需额外训练的情况下，能够实现物体分割。

**主要发现与成果**

研究团队发现，当模型被训练去识别具有非朗伯体（即具有镜面反射、透明等复杂光学特性的）材料的运动物体时，它自然而然地获得了感知第二类运动的能力，这与人类的表现一致。这意味着，人类可能演化出了感知第二类运动的能力，以帮助在复杂的、充满光学噪声的自然环境中更可靠地估计物体的运动。

在实验中，该模型在模仿人类对各种运动现象（包括一些视觉错觉）的感知方面表现出色，并且在精确的光流估计方面也达到了与顶尖CV模型相当的水平。更重要的是，该模型在处理包含反光、折射等复杂光学效应的自然场景时，展现出更强的鲁棒性和稳定性。

**意义与应用前景**

这项研究不仅在理论上揭示了第二类运动感知在理解自然物体运动中的重要作用，也为开发更接近人类视觉能力的人工智能提供了新的途径。这种“人机对齐”的AI模型，在自动驾驶、机器人视觉、增强现实等领域具有广阔的应用前景，能够帮助机器更好地理解和适应复杂多变的真实世界。

#人工智能 #计算机视觉 #运动感知 #仿生学AI #第二类运动