标题：CLAM：无需专家数据，让机器人从无标签视频中学会精细动作


近年来，人工智能领域的大模型在自然语言处理和计算机视觉方面取得了显著进展，这很大程度上归功于海量数据的训练。然而，在机器人学习领域，获取大量带有动作标签的专家演示数据成本高昂，限制了机器人策略的扩展。本文介绍的CLAM（Continuous Latent Action Models）方法，旨在利用大量无标签的视频数据，让机器人能够像人类一样，通过观看视频学习技能。

**研究动机与背景**
互联网上存在着海量的视频资源，这些视频蕴含着丰富的关于物理世界和任务执行的信息。如何有效地利用这些无标签的视频数据来训练机器人策略，是一个重要的研究方向。CLAM方法着重解决从视频数据中学习时面临的一个主要问题：缺乏低层次的动作标签，这使得传统的强化学习和模仿学习方法难以应用。

**方法与技术亮点**
CLAM的核心思想是学习一个“潜在动作模型”（Latent Action Model，LAM），该模型能够为无标签的视频数据自动生成伪动作标签。CLAM包含两个关键组成部分：
1.  **连续潜在动作标签**：与以往方法不同，CLAM使用连续的潜在动作表示，而不是离散的表示。这对于需要精细动作控制的复杂机器人任务至关重要。
2.  **联合训练动作解码器**：CLAM同时训练一个动作解码器，将潜在动作空间映射到真实的机器人动作空间。重要的是，动作解码器可以使用少量非最优的“play data”进行训练，无需昂贵的专家数据。

CLAM的训练过程分为两个阶段：
*   **阶段1：潜在动作模型训练**。CLAM预训练一个潜在动作模型（LAM），用于为无标签数据添加伪动作标签。LAM由正向动力学模型（FDM）和逆向动力学模型（IDM）组成。IDM推断连续观测之间的潜在动作，而FDM预测给定当前观测和潜在动作的下一个观测。通过未来观测重构的自监督目标来学习潜在动作空间。
*   **阶段2：潜在动作策略训练**。利用预训练的IDM为专家演示数据（但没有动作标签）标注潜在动作。然后，使用模仿学习训练潜在动作策略，以预测给定观测的潜在动作。在推理时，策略预测潜在动作，动作解码器将其解码为环境动作。

**主要发现与成果**
研究人员在DMControl（运动控制）、MetaWorld（操作）以及真实的WidowX机器人手臂上验证了CLAM的有效性。实验结果表明，CLAM显著优于现有的方法，在任务成功率方面实现了2-3倍的提升。更重要的是，CLAM能够在没有专家动作标签数据的情况下，学习到高性能的控制策略。

**意义与应用前景**
CLAM的突破在于它能够利用大量的无标签视频数据来训练机器人策略，从而降低了对昂贵的人工标注数据的依赖。这项研究为机器人学习开辟了一条新的道路，有望推动机器人在更广泛的领域中应用。例如，机器人可以通过观看YouTube上的烹饪视频学习新的菜谱，或者通过观看维修视频学习如何修理设备。

标签：#机器人学习 #模仿学习 #无监督学习 #潜在动作模型 #连续控制