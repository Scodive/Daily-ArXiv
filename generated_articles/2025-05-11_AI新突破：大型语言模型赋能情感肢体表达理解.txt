标题：AI新突破：大型语言模型赋能情感肢体表达理解


在人机交互领域，机器理解人类情感至关重要。传统情感识别主要依赖面部表情和语音，但在用户远离摄像头或没有麦克风时会遇到挑战。通过全身运动识别情感是另一种重要途径，且更易于远程数据采集。本文介绍了一种新颖的方法，利用大型语言模型（LLM）理解情感肢体表达，不仅能识别情感，还能生成文本解释，为情感识别提供更深入的理解。

**研究动机与背景**

现有基于骨骼的情感识别方法主要关注提高分类准确率，却忽略了提供支持分类的文本解释。此外，由于数据采集方式的差异，3D骨骼数据集往往是异构的，关节数量和帧长各不相同，阻碍了数据集间的有效知识迁移。受LLM在各个领域取得的显著成果启发，研究者们希望利用LLM作为情感识别器，不仅能从骨骼数据中分类情感，还能生成相应的分类标准。

**方法与技术亮点**

为了解决这些挑战，研究者们提出了一个由大型语言模型驱动的情感-动作解释器（EAI-LLM）。EAI-LLM的关键创新点包括：

1.  **多粒度骨骼分词器（MGST）**：为了增强token的多样性，MGST分别从骨骼数据中提取时空token和语义token，使LLM能够生成更细粒度的情感描述。具体来说，MGST首先对骨骼特征进行时空池化，然后通过全连接层获得语义token，封装了全局身体运动编码信息。同时，MGST还提取时空token，利用时间池化和空间池化分别聚合骨骼特征在时间和空间上的动态信息。
2.  **统一骨骼token模块（UST）**：为了解决异构数据集带来的挑战，UST模块将骨骼序列视为一种特殊的语言，利用掩码机制将不同长度的token归一化到统一长度，从而实现异构数据集的联合训练。
3.  **骨骼-语言对齐**：通过对比学习，将骨骼特征空间与语言特征空间对齐，提高骨骼token与LLM的兼容性。

**主要发现与成果**

实验结果表明，EAI-LLM的识别准确率与现有方法相当。更重要的是，在LLM背景知识的支持下，即使在有限的标记骨骼数据上训练，EAI-LLM也能根据分类结果生成详细的情感描述。例如，当输入一个“羞愧”的骨骼序列时，EAI-LLM可以生成“这个人很羞愧，头低着，双手捂着脸，表现出大量的羞愧”这样的描述。

**意义与应用前景**

EAI-LLM的提出，为情感识别领域带来了新的视角。它不仅能识别情感，还能提供可解释的文本描述，极大地拓展了模型的应用场景。例如，在人机交互中，EAI-LLM可以帮助机器更好地理解用户的情感状态，从而提供更个性化的服务。此外，EAI-LLM还可以应用于心理学研究、动画制作等领域。

标签：#人工智能 #情感识别 #大型语言模型 #肢体表达 #人机交互