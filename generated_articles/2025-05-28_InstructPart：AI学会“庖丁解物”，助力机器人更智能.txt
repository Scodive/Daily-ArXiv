标题：InstructPart：AI学会“庖丁解物”，助力机器人更智能


近年来，大型多模态模型在语言和视觉领域取得了显著进展，推动了机器人、自动驾驶等领域的发展。然而，这些模型通常将物体视为一个整体，忽略了其组成部分。为了让AI更好地理解物体及其各部分的功能，卡内基梅隆大学的研究人员提出了InstructPart，这是一个新的真实世界基准，旨在评估模型在理解和执行日常环境中零件级别任务的能力。

这项研究的动机在于，现有的视觉语言模型（VLM）虽然在识别整个物体方面表现出色，但在识别物体的精细部件以及理解这些部件的功能方面存在不足。例如，当给定“加水”的任务和水壶的图像时，系统不仅需要识别水壶，还需要识别壶盖、壶嘴、把手等部件，并理解这些部件与“加水”任务之间的关系。InstructPart数据集包含2400张图像，涵盖48个物体类别和44个部件类别，并附带了人工标注的分割掩码、任务指令、部件查询和功能描述。

研究人员提出了两个不同的任务来评估模型的性能：任务推理部件分割（TRPS）和Oracle指代部件分割（ORPS）。TRPS要求模型根据任务指令识别特定部件，例如“找到用于拉开微波炉的部件”。ORPS则要求模型根据部件查询识别物体部件，例如“微波炉的把手”。实验结果表明，即使是最先进的VLM，在理解自然语言并将其准确地应用于各种物体和部件时，仍然存在明显的不足。

为了展示InstructPart数据集的潜力，研究人员还提出了一个简单的基线模型，通过使用该数据集进行微调，性能提高了近一倍。这项研究的意义在于，它强调了VLM不仅要在物体层面理解，还要擅长识别精细的部件层面细节的重要性。通过使用InstructPart数据集，有望推动机器人技术，特别是辅助机器人、操作任务、物体分割、虚拟现实和功能学习等领域的发展。研究人员希望InstructPart能够促进任务导向的部件分割研究，并增强VLM在各个领域的适用性。

标签：#人工智能 #计算机视觉 #部件分割 #机器人 #数据集