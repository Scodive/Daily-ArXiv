标题：AI新技能：让模型“教自己”学习，解决无答案难题


在人工智能飞速发展的今天，我们常常依赖大量标注数据来训练模型，但如果遇到没有标准答案的问题，比如创意写作或复杂的咨询建议，该怎么办？近期一项来自Meta Superintelligence Labs等机构的研究，提出了一种名为“Compute as Teacher”（CaT）的新方法，巧妙地将模型自身的“思考过程”转化为学习的动力，为解决这类“无监督”难题提供了新思路。

这项研究的核心在于，它试图回答一个关键问题：当没有“正确答案”时，学习信号从何而来？CaT方法的核心创新在于，它不依赖外部的人类标注，而是利用模型在生成答案时的“探索”过程。具体来说，当模型需要回答一个问题时，它会同时生成多个可能的答案（称为“平行rollouts”）。然后，一个固定的“锚点”模型（通常是初始模型）会审视这些不同的答案，找出其中的共同点、遗漏之处以及矛盾之处，从而“合成”出一个更优的参考答案。这个合成过程就像一位经验丰富的老师，通过分析学生的多种解题思路，提炼出最佳的学习路径。

这种合成的参考答案随后被转化为奖励信号，用于指导模型的进一步学习。对于数学这类有明确答案的任务，研究人员可以进行程序化的验证，确保合成答案与最终结果一致。而对于更开放、更主观的任务，CaT则引入了“自拟评分标准”（self-proposed rubrics）的概念。模型会根据合成的参考答案，生成一系列可验证的二元标准，然后由另一个独立的AI“裁判”来评估实际答案是否符合这些标准。这种方法避免了直接依赖单一AI裁判可能带来的偏见，通过分解问题，提供更精细化的反馈。

CaT的独特之处在于，它并非简单地从多个答案中挑选一个“最佳”的，而是主动地“创造”一个可能比所有原始答案都更好的参考。研究表明，这种方法不仅能提升现有模型的性能，例如在MATH-500数学测试和HealthBench健康咨询评估中，Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B等模型都获得了显著提升，而且在结合强化学习（CaT-RL）后，训练出的模型甚至能超越最初的“老师”信号。

这项研究的意义深远。它证明了“计算力本身可以成为一种监督信号”，为那些缺乏标注数据或答案存在争议的领域，如医疗诊断辅助、法律咨询、创意内容生成等，开辟了新的训练范式。通过让模型“教自己”，CaT不仅降低了对昂贵人工标注的依赖，还可能为AI解锁超越人类数据限制的潜力，迈向更高级别的智能。

#人工智能 #大模型 #无监督学习 #强化学习 #AI教育