标题：大型语言模型代码生成难题：结构性重复及RPG解决方案


随着神经网络语言模型的兴起，代码生成性能得到了显著提升。然而，生成过程中重复出现的问题仍然存在。此前的研究主要集中在内容重复上，但这只是代码生成中更广泛的重复问题的一小部分。更普遍和更具挑战性的问题是结构性重复。在结构性重复中，重复的代码以各种模式出现，但具有固定的结构，这可以内在的反映在语法中。本文正式定义了结构性重复，并提出了一种名为RPG（Repetition Penalization based on Grammar，基于语法的重复惩罚）的高效解码方法，以减轻LLM代码生成中的重复问题。

**研究动机与背景**：
大型语言模型（LLMs）在代码生成方面取得了显著进展，但重复性问题严重影响了代码质量。现有研究主要关注内容重复，即代码片段的简单复制。然而，研究表明，结构性重复——具有相似语法结构的代码段的重复出现——更为常见且难以解决。结构性重复不仅导致代码冗余，还可能导致编译错误和功能缺失。

**方法与技术亮点**：
为了解决结构性重复问题，研究者提出了RPG方法。RPG的核心思想是利用代码的语法结构来识别和惩罚重复模式。具体来说，RPG包含以下几个关键步骤：
1.  **语法规则归约**：利用下推自动机（PDA）将生成的代码归约为其底层语法规则。由于不同的代码片段具有相同的结构模式，因此可以由相同的语法规则表示，RPG 使用基于语法规则构建的下推自动机来检测生成过程中的重复问题。
2.  **重复检测**：使用后缀数组和最长公共前缀（LCP）数组来高效地检测归约后的语法规则序列中的重复模式。
3.  **重复惩罚**：通过动态调整token的权重来降低重复模式的生成概率。该权重基于重复模式的频率和新近度进行调整，从而鼓励模型生成更多样化的代码。RPG 通过策略性地降低导致重复的关键token的可能性来减轻代码生成中的重复。

**主要发现与成果**：
研究者构建了一个新的数据集CodeRepetEval，用于全面评估代码生成中重复问题的缓解方法。CodeRepetEval 包含三种场景：人工合成、代码生成基准测试和真实世界的存储库。实验结果表明，在CodeRepetEval数据集以及HumanEval和MBPP基准测试中，RPG 的性能明显优于表现最佳的基线，有效地减少了重复并提高了生成的代码的质量。RPG 在各个场景中都显著优于其他基线，尤其是在结束句子生成百分比（EGP）和编译器正确性百分比（CCP）等指标上。

**意义与应用前景**：
RPG方法通过利用代码的语法结构，为解决LLM代码生成中的结构性重复问题提供了一种有效途径。该方法不仅可以提高代码质量，还可以减少计算资源的浪费。此外，RPG方法具有良好的通用性，可以应用于不同的LLM和编程语言。这项研究为未来代码生成领域的研究提供了新的思路，并有望在实际软件开发中发挥重要作用。
标签：#代码生成 #大型语言模型 #结构性重复 #语法分析 #RPG