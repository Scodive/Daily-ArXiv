标题：MICRO-ACT：用可执行的自推理缓解问答中的知识冲突


大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但它们在知识密集型任务中仍然面临挑战。检索增强生成（RAG）系统通过整合外部知识来增强LLM的可靠性，然而，当检索到的信息与LLM固有的参数知识相矛盾时，就会出现知识冲突。本文介绍了一种名为MICRO-ACT的新框架，旨在通过分层行动空间和可执行的自推理来缓解这种冲突，提高问答（QA）的准确性。

**研究动机与背景**

RAG系统虽然能够提升LLM的性能，但知识冲突是一个关键问题。检索系统可能会引入噪声、过时或不正确的信息，从而降低LLM的回答质量。现有的缓解冲突的方法通常直接比较两个知识来源，但这可能会使LLM被无关或冗长的上下文淹没，最终阻碍它们识别和减轻不一致性的能力。MICRO-ACT旨在解决这些局限性，通过自动感知上下文复杂性并将每个知识来源分解为一系列细粒度的比较，实现更精确的冲突检测。

**方法与技术亮点**

MICRO-ACT的核心在于其分层行动空间，该空间由导航行动、功能行动和桥接行动组成。导航行动（如ELICIT）用于从LLM中提取参数知识，功能行动（如ASSERT）用于检测检索到的证据与LLM知识之间的冲突。最关键的是桥接行动，特别是分解行动（DECOMPOSE），它能够细化分析的粒度，将复杂的推理分解为更小的、可管理的操作步骤。这种动态调整粒度的能力是MICRO-ACT的核心创新。

MICRO-ACT还集成了ReAct过程，使LLM能够迭代地思考（Thought）、行动（Action）和观察（Observation），从而自动处理知识冲突。该框架通过动态选择导航、功能和分解行动，确保检测和缓解细微的知识冲突，提高最终输出的可靠性。

**主要发现与成果**

在五个广泛使用的知识冲突基准数据集上的实验表明，MICRO-ACT在QA准确性方面始终优于最先进的基线方法。更重要的是，MICRO-ACT在无冲突问题上也能保持竞争力，这突显了其在实际RAG应用中的价值。研究还发现，MICRO-ACT能够解锁LLM感知复杂性和适应不同环境的潜力，并能有效缓解“过度合理化”问题，即LLM试图将矛盾的信息都视为有效的情况。

**意义与应用前景**

MICRO-ACT的成功表明，通过可执行的自推理和动态粒度调整，可以有效解决RAG系统中的知识冲突。该框架的鲁棒性和在各种数据集上的优越性能使其成为实际RAG部署的有价值的工具。未来的研究可以进一步探索MICRO-ACT在其他知识密集型任务中的应用，并优化其分解策略以提高效率。

标签：#知识冲突 #检索增强生成 #大型语言模型 #问答系统 #自推理