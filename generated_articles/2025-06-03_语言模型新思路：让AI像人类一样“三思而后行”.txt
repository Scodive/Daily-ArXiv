标题：语言模型新思路：让AI像人类一样“三思而后行”


大型语言模型（LLM）的参数和数据量不断增大，但这种“大力出奇迹”的方法正面临瓶颈。受人类在解决复杂问题时反复思考的启发，研究者们提出了一种新颖的训练方法，让语言模型在生成每个token时也能“三思而后行”，从而提升性能。

这项研究的核心在于引入了“pondering（思考）”机制。传统语言模型在预测下一个token时，直接从预测分布中采样。而Pondering LM则不同，它首先根据预测的token分布，计算所有token embedding的加权和，得到一个“pondering embedding”。这个embedding会被反馈回模型，进行下一轮预测，就像人类在表达复杂想法前会反复斟酌一样。

具体来说，模型在生成token的过程中，会多次执行前向传播。每次前向传播后，模型不是直接输出结果，而是生成一个pondering embedding，并将其与原始输入embedding结合，作为下一次前向传播的输入。通过这种迭代的方式，模型可以逐步优化其预测结果。这种方法无需人工标注数据或强化学习，仅通过自监督学习即可实现。

实验结果表明，Pondering LM在多个开源架构（GPT-2、Pythia和LLaMA）上都表现出色。在语言建模任务中，Pondering LM能够以一半的参数量达到与传统模型相当的性能。在9个下游任务中，Pondering Pythia模型的表现也显著优于官方Pythia模型。值得一提的是，Pondering Pythia-1B的性能甚至可以与训练数据量是其10倍的TinyLlama-1.1B相媲美。

这项研究的意义在于，它提供了一种新的模型扩展思路。通过模拟人类的思考过程，Pondering LM提高了模型的参数知识密度，降低了通信成本。更重要的是，这种方法可以与传统的参数扩展和推理时扩展策略相结合，为提升模型性能开辟了新的途径。未来的研究可以探索token自适应的pondering方法，并尝试将该方法应用于更多模型类型和领域。

标签：#自然语言处理 #深度学习 #语言模型 #自监督学习 #模型优化