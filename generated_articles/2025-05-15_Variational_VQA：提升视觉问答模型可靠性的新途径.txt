标题：Variational VQA：提升视觉问答模型可靠性的新途径


近年来，结合视觉和语言能力的多模态模型在视觉问答（VQA）领域取得了显著进展。然而，这些模型常常过度自信、校准不佳，尤其是在面对分布外（OOD）数据时，难以做出正确的“放弃”决策。为了解决这一可靠性问题，本文介绍了一种名为“Variational VQA”的新方法，旨在提高多模态模型的可靠性。

该研究的核心在于使用一种名为IVON（Improved Variational Online Newton）的变分算法来微调视觉-语言模型，而非传统的AdamW优化器。IVON算法能够生成模型参数的后验分布，从而提供模型预测的不确定性估计。这种不确定性估计可以帮助模型在不牺牲准确性的前提下，更好地进行校准和选择性预测（即决定是否放弃回答问题）。

与AdamW微调相比，Variational VQA在多个模型上将预期校准误差（ECE）降低了50%以上，并在固定风险水平下提高了覆盖率。更重要的是，在存在分布偏移的情况下，Variational VQA的性能提升更为显著。当测试集中包含50%的OOD数据时，其覆盖率相较于当前最优方法提高了8%。

Variational VQA的优势在于，它在提高模型可靠性的同时，不会显著增加训练成本。此外，与诸如Laplace近似、随机权重平均（SWA）或MC Dropout等其他贝叶斯方法相比，Variational VQA具有独特的优势，例如不需要额外的数据传递来计算Hessian矩阵，也不需要额外的训练。实验表明，Variational VQA在测试时所需的MC样本数量也少于MC Dropout。

总而言之，Variational VQA为提升多模态模型的可靠性提供了一种可行的选择。通过变分学习，模型能够更好地评估自身预测的不确定性，从而做出更明智的决策，尤其是在面对未知或具有挑战性的场景时。这项研究为未来的多模态模型发展指明了新的方向，有望在实际应用中发挥重要作用。

标签：#视觉问答 #多模态学习 #变分推断 #模型可靠性 #分布外泛化