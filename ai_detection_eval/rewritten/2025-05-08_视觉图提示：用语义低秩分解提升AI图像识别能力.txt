标题：视觉图提示：用语义低秩分解提升AI图像识别能力


近年来，
将图像表示为图结构的视觉图神经网络（ViG）在图像识别领域展现出巨大潜力。
然而，如何高效地将预训练的ViG模型迁移到各种下游任务，仍然是一个挑战。
传统方法需要耗费大量的计算资源和存储空间进行完全微调。
为了解决这个问题，一种名为“视觉提示”（Visual Prompting）的参数高效微调技术应运而生。
然而，现有的视觉提示方法主要针对Transformer架构设计，忽略了ViG中丰富的拓扑关系，限制了其性能。
这篇论文提出了一种新颖的视觉图提示（VGP）框架，专门为视觉图结构量身定制，旨在提升ViG的迁移学习能力。
这项研究的核心洞察在于，视觉图中语义相关的组件具有低秩特性。
这意味着图像的关键语义信息可以被压缩到低维空间中。
基于此，研究者们提出了一种语义低秩提示方法，该方法将语义特征分解为低秩分量，
并将其与视觉图拓扑上的提示相结合，从而捕捉全局结构模式和细粒度的语义依赖关系。
具体来说，VGP包含三个关键组件：语义低秩图提示（SeLo-Graph Prompt），通过添加可训练的虚拟节点并动态形成边，
捕捉全局语义依赖；语义低秩边提示（SeLo-Edge Prompt），利用低秩分解过滤局部细节，促进语义特征在连接节点间的传播；
以及语义低秩节点提示（SeLo-Node Prompt），保留局部细节的同时，增强低秩语义信息。
研究人员在多个下游任务上进行了大量实验，结果表明，VGP显著提高了ViG的迁移性能，在保持参数效率的同时，
取得了与完全微调相当的结果。
例如，在图像分类任务中，VGP在多个数据集上都超越了现有的视觉提示技术，
并且在一些小数据集上甚至超过了完全微调的性能。
这项研究的意义在于，它为视觉图神经网络的参数高效微调提供了一种新的思路。
通过利用视觉图中语义信息的低秩特性，VGP能够在有限的计算资源下，有效地提升ViG的迁移学习能力。
这项技术有望在图像识别、目标检测、图像分割等领域得到广泛应用，尤其是在资源受限的场景下，例如移动设备和嵌入式系统。
此外，该研究也为未来的视觉提示方法设计提供了新的方向，即如何更好地利用图像中的结构化信息。
标签：#视觉图神经网络 #视觉提示 #低秩分解 #迁移学习 #图像识别