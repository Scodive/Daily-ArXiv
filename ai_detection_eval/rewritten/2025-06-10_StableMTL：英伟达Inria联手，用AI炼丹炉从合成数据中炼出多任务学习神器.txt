标题：StableMTL：英伟达Inria联手，用AI炼丹炉从合成数据中炼出多任务学习神器


在计算机视觉领域，
让AI同时学会多项技能（多任务学习，MTL）一直是研究热点。
然而，标注大量真实数据成本高昂，限制了MTL的发展。
近日，英伟达和Inria的研究人员在arXiv上发表了一篇名为"StableMTL:
Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets"的论文，提出了一种新颖的解决方案：
利用预训练的潜在扩散模型（LDMs），仅在部分标注的合成数据集上训练，就能让模型在多个真实世界的视觉任务上表现出色。
这项研究的核心在于如何利用图像生成模型进行密集预测任务。
研究者发现，LDMs强大的泛化能力使其能够适应不同的视觉任务，即使只在合成数据上进行训练。
关键在于如何将LDMs从图像生成器转化为多任务学习的“炼丹炉”。
StableMTL方法主要有两大创新点。
首先，它扩展了部分标注的多任务学习设置，使其能够利用多个合成数据集进行训练，每个数据集只标注了部分任务。
这更贴近现实场景，也更具可扩展性。
其次，StableMTL通过一种多流架构，利用任务注意力机制，促进了任务间的有效信息共享。
传统的N-to-N注意力机制在任务数量增加时会面临扩展性问题，而StableMTL采用的N-to-1注意力机制则更加高效。
更重要的是，该方法采用统一的潜在损失函数，无需为每个任务单独设计损失函数，大大简化了训练过程，提高了可扩展性。
具体来说，StableMTL包含两个训练阶段。
第一阶段，研究人员微调一个用于密集预测的潜在扩散模型，通过任务令牌、统一潜在损失和自定义训练方案，使其适应多任务学习。
第二阶段，为了鼓励任务间的信息交流，他们训练一个独立的任务条件模型，该模型通过任务注意力机制建模任务间的交互。
这种设计使得StableMTL能够处理各种空间和时间任务，而无需繁琐的任务平衡。
实验结果表明，StableMTL在7个任务和8个基准测试中都优于现有方法，实现了显著的性能提升。
即使仅在三个相对较小的合成数据集上进行训练，StableMTL也能很好地泛化到各种真实世界场景，包括未见过的结构和领域。
这项研究为多任务学习提供了一种新的思路，有望降低数据标注成本，推动计算机视觉技术的发展。
标签：#多任务学习 #扩散模型 #合成数据 #计算机视觉 #深度学习