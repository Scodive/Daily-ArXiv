标题：无需重训练！
UC Berkeley提出ViT新方法：
测试时注册（Test-time Registers）提升性能与可解释性


Vision Transformers (ViTs) 在计算机视觉领域取得了显著的成功，但最近的研究表明，
ViTs中存在“高范数（high-norm）token”现象，会导致注意力图谱出现噪声，影响下游任务的性能。
Darcet et al.
(2024) 提出通过训练时加入额外的“注册（register）token”来解决这个问题，但这需要从头重新训练模型。
UC Berkeley 的这项研究表明，无需重新训练，通过一种名为“测试时注册（Test-time Registers）”的创新方法，
也能有效缓解这些问题，提升ViT的性能和可解释性。
**研究动机与背景**

ViT模型在处理图像时，会在图像的某些区域（通常是低信息区域，
如背景）产生具有较高范数的token。
这些token会干扰注意力机制，导致模型关注到不相关的区域，从而影响视觉处理任务。
先前的解决方案需要重新训练模型，成本较高，限制了其应用范围。
这项研究旨在找到一种无需重新训练即可解决高范数token问题的方法。
**方法与技术亮点**

该研究的核心在于发现了一种被称为“注册神经元（register neurons）”的神经元子集。
这些神经元负责产生高范数token。
研究人员发现，通过在模型推理阶段（测试时）操控这些神经元的激活，可以将高范数token转移到新增的、未训练的token上，
从而模拟训练时注册token的效果。
具体来说，该方法包括以下步骤：

1.
**识别注册神经元**：通过算法找出在产生高范数token时激活程度最高的神经元。
2.
**添加测试时注册token**：在输入图像token序列后，添加一个或多个额外的token。
3.
**激活注册神经元**：将注册神经元的激活值转移到新增的注册token上，从而使这些token具有高范数。
这种方法无需修改模型结构或重新训练参数，即可在测试时动态地添加注册机制。
**主要发现与成果**

研究结果表明，使用测试时注册token可以有效地清除注意力图谱中的噪声，
提高模型在各种下游任务上的性能，包括：

*   **无监督对象发现**：在LOST算法中，正确的目标定位性能提升显著。
*   **零样本分割**：基于注意力的零样本分割任务的性能也得到了提升。
*   **视觉语言模型（VLM）**：改善了VLM的注意力机制，提高了模型的可解释性。
*   **防御印刷攻击**：通过将高范数token转移到对抗性区域，提高了模型对印刷攻击的鲁棒性。
更重要的是，测试时注册token的性能与使用训练时注册token的模型相当，但避免了昂贵的重新训练过程。
**意义与应用前景**

这项研究的意义在于提供了一种简单有效的、无需重新训练即可提升ViT模型性能和可解释性的方法。
该方法具有广泛的应用前景，可以应用于各种预训练的ViT模型，包括视觉语言模型，从而提高模型在各种视觉任务中的表现，
并增强模型的可解释性和鲁棒性。
此外，该研究揭示了ViT模型中神经元的一种新的功能——“注册神经元”，为理解深度神经网络的内部机制提供了新的视角。
标签：#视觉Transformer #可解释性 #测试时注册 #高范数Token #深度学习