标题：GeoDrive：3D几何驱动的自动驾驶世界模型，实现精准动作控制


近年来，世界模型在动态环境模拟领域取得了革命性进展，
使系统能够预测未来状态并评估潜在动作。
在自动驾驶领域，这些能力有助于车辆预测其他道路使用者的行为，执行风险感知规划，加速仿真训练，并适应新的场景，
从而提高安全性和可靠性。
然而，目前的方法在保持强大的3D几何一致性或处理遮挡时存在缺陷，这对于自动导航任务中的可靠安全评估至关重要。
为了解决这个问题，论文提出了GeoDrive，它将强大的3D几何条件显式地集成到驾驶世界模型中，以增强空间理解和动作可控性。
具体来说，首先从输入帧中提取3D表示，然后基于用户指定的自车轨迹获得其2D渲染。
为了实现动态建模，在训练期间提出了一个动态编辑模块，通过编辑车辆的位置来增强渲染效果。
GeoDrive的核心在于其混合神经-几何框架，该框架显式地强制执行生成序列中的3D几何一致性。
首先，从单目输入构建3D结构先验，然后沿着用户指定的相机轨迹执行投影渲染，以生成几何接地的条件信号。
进一步采用级联视频扩散来通过3D注意去噪来细化这些投影，从而共同优化光度质量和几何保真度。
对于动态对象，引入了一个物理引导的编辑模块，该模块在显式运动约束下转换代理外观，以确保物理上合理的交互。
实验结果表明，GeoDrive在动作精度和3D空间感知方面显著优于现有模型，
从而为更安全的自动驾驶带来更逼真、适应性更强和更可靠的场景建模。
此外，该模型可以推广到新的轨迹，并提供交互式场景编辑功能，例如对象编辑和对象轨迹控制。
与Vista模型相比，GeoDrive将自车动作可控性提高了，轨迹跟踪误差降低了42%。
此外，它在视频质量指标（包括LPIPS，PSNR，SSIM，FID和FVD）方面取得了显著的提升。
此外，该模型有效地推广到新的视图合成任务，在生成的视频质量方面超过了StreetGaussian。
除了轨迹调节外，GeoDrive还提供交互式场景编辑功能，例如动态对象插入，替换和运动控制。
此外，通过将实时视觉输入与预测建模相结合，增强了视觉语言模型的决策过程，从而提供了一个交互式仿真环境，从而实现了更安全，
更有效的轨迹规划。
标签：#自动驾驶 #世界模型 #3D几何 #视频生成 #动作控制