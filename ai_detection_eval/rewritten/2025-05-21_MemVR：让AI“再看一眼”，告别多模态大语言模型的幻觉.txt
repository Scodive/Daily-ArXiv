标题：MemVR：让AI“再看一眼”，
告别多模态大语言模型的幻觉


多模态大语言模型（MLLM）在处理图像、文本等多种信息方面表现出色，
但它们也容易产生“幻觉”，即生成与输入不符的内容。
为了解决这个问题，一篇新的研究论文提出了一种名为MemVR（Memory-Space Visual Retracing）的创新方法，
它模仿了人类“再看一眼”的认知过程，显著减少了MLLM的幻觉现象。
**研究动机与背景**

MLLM的幻觉问题，例如生成不存在的物体或做出矛盾的判断，会严重影响其可靠性，
尤其是在医疗、自动驾驶等安全攸关的领域。
研究者认为，这可能是由于模型对视觉和文本信息的理解存在不平衡，导致在整合多模态信息时产生偏差。
现有的解决方法，如检索增强生成（RAG）和微调等，往往会增加计算负担或存储需求。
而注意力干预和对比解码（CD）等策略，也存在推理延迟高或引入噪声等问题。
**方法与技术亮点**

MemVR的核心思想是，当模型对图像的记忆模糊时，就让它“再看一眼”。
具体来说，MemVR将视觉tokens作为补充证据，通过前馈神经网络（FFN）重新注入到MLLM中，充当“键-值记忆”。
这种“再看一眼”的机制在模型推理过程中，当模型表现出高度不确定性时触发，从而有效地增强事实对齐。
论文中提到，普通的FFN可以被认为是通过输入x作为query，与key计算相似度，然后找到匹配的value，通过相似度聚集value，
这可以被认为是一种键值记忆。
MemVR将视觉tokens重新注入到FFN中，可以被认为是一种简化和高效的信息重新检索过程。
MemVR不需要额外的训练，且计算量可以忽略不计。
MemVR还提出了静态和动态两种视觉重溯（VR）策略。
静态VR通过验证集选择最佳的触发层，而动态VR则根据模型在推理过程中的不确定性，动态地选择触发VR的层。
**主要发现与成果**

实验结果表明，MemVR在各种MLLM中都能显著减少幻觉，并在通用基准测试中表现出色，
且不会增加额外的时间开销。
例如，在POPE基准测试中，MemVR的准确率提高了7.0%，在CHAIR I指标上提高了15.6%，在MME基准测试中总分提高了32.2分。
**意义与应用前景**

MemVR的提出，为解决MLLM的幻觉问题提供了一种高效、简洁的解决方案。
它不仅提高了模型的准确性和可靠性，还具有良好的通用性和可扩展性，可以应用于各种MLLM架构。
此外，MemVR的设计理念也为未来的研究提供了新的思路，例如，可以将其扩展到其他模态，如音频、空间感知等。
标签：#多模态大语言模型 #幻觉缓解 #机器视觉 #人工智能 #深度学习