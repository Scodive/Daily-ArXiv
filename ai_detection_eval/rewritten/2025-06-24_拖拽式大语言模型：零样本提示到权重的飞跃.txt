标题：拖拽式大语言模型：零样本提示到权重的飞跃


近年来，大型语言模型（LLMs）在自然语言处理领域取得了显著进展。
然而，针对特定任务对LLMs进行定制化微调的成本仍然很高。
本文解读的论文《Drag-and-Drop LLMs:
Zero-Shot Prompt-to-Weights》提出了一种名为“拖拽式LLMs (DnD)”的全新方法，它无需针对每个任务进行单独的训练，
而是直接将少量无标签的任务提示映射到LoRA权重更新，从而极大地降低了定制LLMs的成本和时间。
**研究动机与背景**

传统的参数高效微调（PEFT）方法，如LoRA，虽然降低了定制LLMs的成本，
但仍然需要为每个下游数据集进行单独的优化运行。
这在需要大规模部署PEFT时，会成为计算瓶颈。
DnD的核心思想是：LoRA适配器本质上是训练数据（即提示）的函数，如果可以直接学习从提示到权重的映射，
就可以完全绕过梯度下降。
**方法与技术亮点**

DnD利用一个轻量级的文本编码器将每个提示批次提炼成条件嵌入，
然后通过一个级联的超卷积解码器将其转换为完整的LoRA矩阵集合。
这种方法的核心在于prompt-conditioned parameter generation，即提示条件参数生成。
具体来说，DnD包含以下几个关键步骤：

1.
**数据准备**：收集各种数据集上训练好的LoRA适配器，并将这些适配器与来自其训练数据的prompt批次随机配对。
2.
**提示嵌入**：使用预训练的文本编码器（如Sentence-BERT）从prompt中提取嵌入向量，作为参数生成器的输入。
3.
**参数生成**：使用一个超卷积解码器，将prompt嵌入转换为LoRA权重更新。
解码器采用级联的卷积块结构，能够高效地生成大规模参数。
4.
**训练与推理**：训练参数生成器，使其能够根据输入的prompt嵌入生成相应的LoRA权重。
在推理阶段，只需将来自新数据集的prompt输入到参数生成器中，即可快速获得针对该数据集定制的LLM参数。
**主要发现与成果**

实验结果表明，DnD在常识推理、数学、代码生成和多模态基准测试中，与最强的训练LoRA相比，
在未见数据集上的性能平均提升高达30%，同时将适应开销降低了高达12,000倍。
此外，DnD还表现出强大的跨领域泛化能力，即使从未见过目标数据或标签，也能取得良好的效果。
**意义与应用前景**

DnD的成功挑战了梯度下降对于模型专业化来说是不可或缺的这一观念，并开辟了一条新的道路，
即权重本身成为一种新的数据模态和生成目标，并以简洁的任务描述符为条件。
这项研究成果对于快速定制LLMs，降低计算成本，以及实现更广泛的LLM应用具有重要意义。
未来，可以进一步探索如何将DnD扩展到更大的模型，以及如何利用互联网上现有的预训练checkpoint来提高参数生成器的实用性。
标签：#大语言模型 #参数高效微调 #零样本学习 #模型生成 #人工智能