标题：AI推理新突破：人大、上海AI实验室揭示大模型“思考”秘密，关键在于这些“思考词”！
大型推理模型（LRMs）在解决复杂问题上展现出令人印象深刻的能力，但它们内部的推理机制却像一个“黑箱”，鲜为人知。
近日，中国人民大学和上海人工智能实验室等机构的研究人员，在预印本平台arXiv上发表了一篇题为《Demystifying Reasoning Dynamics with Mutual Information:
Thinking Tokens are Information Peaks in LLM Reasoning》的论文。
该研究从信息论的独特视角，深入剖析了LRMs的推理过程，揭示了模型在“思考”时会产生“信息高峰”，
并发现这些高峰与特定的“思考词”紧密相关，为理解和提升大模型的推理能力提供了全新的见解和实用方法。
**揭开“黑箱”：推理过程中的信息高峰**

当前，大型语言模型（LLMs）的推理能力，
如在数学、编程和逻辑推理等复杂任务中的表现，已成为其最强大和关键的能力之一。
然而，这些模型是如何一步步得出答案的，其内部动态和中间步骤对最终结果的影响，仍然是个谜。
为了解开这个“黑箱”，研究团队引入了“互信息”（Mutual Information, MI）的概念。
简单来说，互信息衡量的是两个变量之间共享的信息量。
在这里，研究人员追踪了模型在推理过程中，
其每个中间表示（即模型在生成每个词时的内部状态）与正确答案之间互信息的变化。
令人惊讶的是，研究发现，在LRMs的推理轨迹中，互信息会在某些特定的生成步骤突然且显著地增加，
形成一个个“信息高峰”（MI Peaks）。
这些高峰在整个推理过程中分布稀疏且不均匀，占比通常不超过5%。
这表明，在这些关键时刻，模型内部的表示包含了与正确答案高度相关的信息。
研究团队进一步从理论上证明，互信息越高，模型预测错误的概率就越低，这意味着这些信息高峰确实与模型的推理性能息息相关。
值得注意的是，这种清晰的信息高峰现象在未经推理强化训练的基础LLMs中并不明显，
这暗示了信息高峰的出现可能源于LRMs特有的推理密集型训练。
**“思考词”：信息高峰的语义载体**

那么，这些信息高峰究竟对应着模型在“思考”什么？
研究人员将这些高互信息步骤的内部表示解码成具体的词汇，结果发现，
这些“信息高峰”对应的词汇大多是表达反思、自我纠正或逻辑转换的连接词和语气词，
例如“Wait”（等等）、“Hmm”（嗯）、“Therefore”（因此）、“So”（所以）等。
研究团队将这些词形象地命名为“思考词”（Thinking Tokens）。
为了验证这些“思考词”对模型推理性能的关键作用，研究人员进行了一项对照实验：在模型推理时，
刻意抑制这些“思考词”的生成。
结果显示，完全抑制这些“思考词”会显著损害模型的推理性能，而随机抑制相同数量的其他词汇则几乎没有影响。
这有力地证明了“思考词”对于LRMs实现卓越推理能力的重要性。
它们不仅在语言上引导模型进行多步骤推理和自我修正，其对应的内部表示也确实承载了与正确答案高度关联的信息。
**实战应用：两大策略提升推理表现**

基于这些深刻的发现，
研究团队提出了两种简单而有效的、无需额外训练即可提升LRMs推理性能的方法：

1.
**表示循环（Representation Recycling, RR）**：既然信息高峰处的表示富含关键信息，那么让模型更充分地利用它们如何？
RR方法在模型生成“思考词”时，将其对应的内部表示重新输入到模型中，
允许模型对这些高信息量的表示进行多次迭代处理。
实验表明，RR在多个数学推理基准测试中持续提升了LRMs的性能。
例如，在AIME24这一高难度竞赛级数学数据集上，它相对提升了DeepSeek-R1-Distill-LLaMA-8B模型的准确率达20%。
2.
**基于思考词的测试时扩展（Thinking Token based Test-time Scaling, TTTS）**：当有额外计算预算时，
如何让模型更有效地“思考”？
TTTS方法在模型完成初步输出后，强制其以一个“思考词”开始，继续生成额外的推理步骤。
实验结果表明，在相同的token预算下，TTTS持续优于原始LRMs。
特别是在更长的推理过程中，当原始模型的性能趋于饱和时，TTTS仍能稳步提升性能，有效促使LRMs进行更深入的思考。
这项研究不仅为我们理解大型推理模型的内部工作机制打开了一扇窗，更提供了切实可行的优化方案。
通过揭示“信息高峰”和“思考词”的奥秘，未来我们有望开发出更透明、更高效、更值得信赖的AI推理系统。
标签：#大语言模型 #人工智能 #推理能力 #信息论 #AI研究