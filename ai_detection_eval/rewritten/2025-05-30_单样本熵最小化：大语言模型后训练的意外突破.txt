标题：单样本熵最小化：大语言模型后训练的意外突破


大型语言模型（LLMs）的后训练阶段发展迅速，
涌现出许多具有卓越推理能力的模型。
然而，传统的强化学习（RL）方法需要大量高质量标注数据和精心设计的奖励机制，过程繁琐且成本高昂。
本文介绍的一项研究表明，一种名为“单样本熵最小化”（One-shot Entropy Minimization，简称EM）的全新方法，
仅需单个未标注数据和极少的优化步骤，即可在性能上超越传统强化学习。
这一发现或将颠覆我们对大语言模型后训练范式的认知。
这项研究的核心在于利用熵最小化（EM）来消除训练中的随机性，从而确保实验结果的可靠性。
研究人员训练了13,440个大型语言模型，结果表明，仅使用一个未标注数据样本，EM的性能就超过了传统的强化学习方法，
并且通常在10个训练步骤内即可收敛，远快于强化学习所需的数千步。
EM基于两个简单直接的假设：一是大语言模型的生成过程本质上是随机的；
二是正确的答案通常比错误的答案具有更低的熵。
该研究揭示了EM和RL的共同目标：在不增加新知识的情况下，释放预训练模型的潜在能力，
二者都依赖于“token reranking”（词元重排序）过程来最大化模型性能。
研究的主要贡献包括：提出了一种强大的全无监督方法——单样本熵最小化，
它仅使用单个未标注数据即可媲美甚至超越强化学习；深入分析了单样本EM的有效性，发现它与RL具有许多核心属性，
但在logits shift（logits偏移）方面表现出相反的趋势；广泛评估了EM，并确定温度是训练和推理的关键因素，
EM在推理时温度方面与RL表现出相反的趋势；通过分析损失-推理曲线的不一致性和EM的logits偏移效应，
揭示了EM是一种分布塑造工具，而非学习方法。
具体来说，EM算法通过最小化模型在每个生成步骤中token级别的条件熵来减少模型预测的不确定性。
为了避免惩罚prompt部分，仅计算生成token的熵。
为了筛选出更有效的数据，研究采用了基于方差的数据选择策略，选择模型行为方差最高的prompt。
实验结果表明，将单样本EM应用于Qwen2.5-Math-7B基础模型后，在所有评估的数学推理基准测试中都观察到显著的性能提升。
例如，在MATH500上的性能显著提高了25.8个百分点（从53.0到78.8）。
这项研究表明，熵最小化具有巨大的潜力，可以增强基础语言模型在数学推理任务中的性能，
为大语言模型的后训练提供了一种高效且简便的新思路。
未来的研究可以集中在稳定EM训练、探索EM的全部潜力以及将EM与其他后训练技术相结合等方面。
标签：#大语言模型 #熵最小化 #后训练 #强化学习 #数学推理