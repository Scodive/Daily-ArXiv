标题：Molmo：开源数据与权重打造的顶尖视觉语言模型


今天最先进的视觉语言模型（VLM）仍然是闭源的，
这限制了科学研究的透明度和可复现性。
为了打破这一局面，本文介绍了一种新的VLM家族Molmo，它在同等开放程度的模型中达到了最先进水平。
Molmo的关键在于PixMo，这是一个全新的数据集集合，包括用于预训练的详细图像描述、用于微调的自由形式图像问答数据集，
以及创新的2D指向数据集，所有这些数据均未使用外部VLM生成。
**研究动机与背景**

目前，最强大的开源VLM依赖于闭源VLM生成的合成数据，
这实际上是将闭源VLM的能力提炼到开源模型中。
因此，学术界缺乏从零开始构建高性能VLM的基础知识。
Molmo旨在填补这一空白，提供完全开源的VLM构建方案。
**方法与技术亮点**

Molmo的成功依赖于三个关键因素：精心的模型选择、良好调整的训练流程，以及高质量的新数据集PixMo。
PixMo包含以下几个部分：

*   **详细图像描述数据集**：包含71.2万张图像，每张图像都配有超过200个单词的详细描述。
为了避免人工撰写描述的低效和对闭源VLM的依赖，研究人员采用了一种新颖的方法：让标注者口述图像内容，
然后再将录音转录为文本。
*   **自由形式图像问答数据集**：包含7.3万张图像和16.2万个问答对。
为了确保问答质量，研究人员让人工标注者与语言模型交互，对答案进行编辑和完善。
*   **2D指向数据集**：包含22.3万张图像和230万个指向标注。
这种数据能够让模型理解图像中特定区域与文本之间的对应关系，从而提高模型在定位、计数等任务中的表现。
*   **合成数据集**：为了增强模型在特定技能方面的能力，研究人员还创建了多个合成数据集，
例如时钟读取、图表理解等。
**主要发现与成果**

Molmo-72B模型在学术基准测试中取得了最高分，并在人工评估中仅次于GPT-4o。
Molmo不仅优于其他开源模型，还超越了许多闭源模型，包括Claude 3.5 Sonnet和Gemini 1.5 Pro/Flash。
**意义与应用前景**

Molmo的发布为VLM的研究和应用开辟了新的可能性。
开源的权重、数据和代码能够促进学术界的合作和创新，加速VLM技术的发展。
此外，Molmo在图像描述、问答和定位等任务中的出色表现，
也使其在机器人、自动驾驶、智能助手等领域具有广阔的应用前景。
标签：#视觉语言模型 #开源 #数据集 #人工智能 #深度学习