标题：LLM测试时扩展新思路：概率论视角下的提示策略再思考


近年来，大型语言模型（LLM）的推理能力备受关注。
研究者们尝试通过扩展测试时的计算量来提升LLM的推理能力。
然而，不同提示策略在计算量扩展时的表现差异却鲜有研究。
本文从概率论的角度出发，重新审视了LLM测试时扩展中提示策略的角色，并提出了新的优化方法。
**研究动机与背景**

现有的研究主要集中在如何设计更复杂的提示策略来提高LLM的初始性能。
然而，在实际应用中，计算资源是有限的。
当给予LLM更多的计算资源（例如，通过多次采样进行多数投票）时，哪种提示策略能够发挥最佳效果？
这项研究旨在回答这个问题，并为LLM测试时扩展提供更有效的策略选择依据。
**方法与技术亮点**

该研究的核心在于对LLM在多数投票场景下的测试时扩展行为进行了系统性的实验分析和理论证明。
研究者们首先在6个LLM（包括开源和闭源模型）和6个推理基准上，对8种主流提示策略进行了大规模实验。
实验结果表明，随着采样时间和计算开销的增加，初始性能优越的复杂提示策略逐渐落后于简单的思维链（Chain-of-Thought,
CoT）提示。
为了解释这一现象，研究者们从概率论的角度进行了深入分析，并提出了理论证明。
他们认为，CoT策略更易于回答简单问题，且不易受到错误答案的干扰。
基于此，研究者们还提出了一种基于概率论的方法，能够快速准确地预测扩展性能，并在无需额外资源消耗的情况下选择最佳策略。
该方法可以作为多数投票场景下的测试时扩展定律。
此外，研究还基于理论分析，提出了两种显著提升扩展性能的方法：一是根据问题难度自适应地调整采样次数；
二是动态地选择最优的提示策略。
实验验证了这些方法的有效性，例如，在GSM8K和MATH-500数据集上，通过结合这两种方法，
LLaMA-3-8B-Instruct模型的多数投票准确率分别从86.0%提升至97.4%和从15.2%提升至61.0%。
**主要发现与成果**

*   CoT策略在测试时扩展中表现出强大的潜力，即使其初始性能可能不如其他复杂策略。
*   概率论分析能够有效解释不同提示策略在扩展时的行为差异。
*   提出的预测方法能够准确估计扩展性能，并指导最佳策略选择。
*   自适应采样和动态策略选择能够显著提升扩展性能。
**意义与应用前景**

这项研究颠覆了人们对复杂提示策略的固有认知，强调了简单CoT策略在测试时扩展中的潜力。
研究成果为LLM的实际应用提供了新的思路，有助于在有限的计算资源下，充分发挥LLM的推理能力。
此外，提出的预测方法和优化策略也为未来的研究方向提供了新的启示。
标签：#大型语言模型 #提示工程 #测试时扩展