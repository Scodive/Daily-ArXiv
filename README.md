## Latest arXiv Papers

- 2025-06-07 [强化Token优化：DPO与PPO的巧妙融合，提升RLHF性能](generated_articles/2025-06-07_强化Token优化：DPO与PPO的巧妙融合，提升RLHF性能.txt)
- 2025-06-06 [MICRO-ACT：用可执行的自推理缓解问答中的知识冲突](generated_articles/2025-06-06_MICRO-ACT：用可执行的自推理缓解问答中的知识冲突.txt)
- 2025-06-06 [R2EC：让推荐模型像人一样“思考”](generated_articles/2025-06-06_R2EC：让推荐模型像人一样“思考”.txt)
- 2025-06-06 [TextCenGen：AI助力，让文本与图像和谐共生](generated_articles/2025-06-06_TextCenGen：AI助力，让文本与图像和谐共生.txt)
- 2025-06-06 [AI进化论：达尔文遇上哥德尔，自改进AI的全新尝试](generated_articles/2025-06-06_AI进化论：达尔文遇上哥德尔，自改进AI的全新尝试.txt)
- 2025-06-05 [AI行为预测的极限：理论揭示认知推断的边界](generated_articles/2025-06-05_AI行为预测的极限：理论揭示认知推断的边界.txt)
- 2025-06-05 [Molmo：开源数据与权重打造的顶尖视觉语言模型](generated_articles/2025-06-05_Molmo：开源数据与权重打造的顶尖视觉语言模型.txt)
- 2025-06-05 [AnySplat：无需相机标定的多视角3D高斯溅射新方法](generated_articles/2025-06-05_AnySplat：无需相机标定的多视角3D高斯溅射新方法.txt)
- 2025-06-05 [Surfer-H：开源模型驱动的低成本高效能网页智能代理](generated_articles/2025-06-05_Surfer-H：开源模型驱动的低成本高效能网页智能代理.txt)
- 2025-06-05 [语言模型记忆力大揭秘：容量极限与泛化之谜](generated_articles/2025-06-05_语言模型记忆力大揭秘：容量极限与泛化之谜.txt)
- 2025-06-04 [MMaDA：多模态扩散语言模型的新突破](generated_articles/2025-06-04_MMaDA：多模态扩散语言模型的新突破.txt)
- 2025-06-04 [AI新突破：CrossFlow实现跨模态数据“无缝衔接”](generated_articles/2025-06-04_AI新突破：CrossFlow实现跨模态数据“无缝衔接”.txt)
- 2025-06-04 [AI模型训练新发现：模仿专家不如自主探索](generated_articles/2025-06-04_AI模型训练新发现：模仿专家不如自主探索.txt)
- 2025-06-03 [AI新突破：RISE模型学会自我检查，解题能力更上一层楼](generated_articles/2025-06-03_AI新突破：RISE模型学会自我检查，解题能力更上一层楼.txt)
- 2025-06-03 [语言模型新思路：让AI像人类一样“三思而后行”](generated_articles/2025-06-03_语言模型新思路：让AI像人类一样“三思而后行”.txt)
- 2025-06-03 [LLM与人类的认知差异：压缩与意义的权衡](generated_articles/2025-06-03_LLM与人类的认知差异：压缩与意义的权衡.txt)
- 2025-06-02 [SaP：用几何约束为大语言模型保驾护航](generated_articles/2025-06-02_SaP：用几何约束为大语言模型保驾护航.txt)
- 2025-06-02 [AI“新语”：用新词解锁人机沟通的未来](generated_articles/2025-06-02_AI“新语”：用新词解锁人机沟通的未来.txt)
- 2025-06-02 [RISE：让AI学会自我反思，解题能力更上一层楼](generated_articles/2025-06-02_RISE：让AI学会自我反思，解题能力更上一层楼.txt)
- 2025-06-02 [NEXUS_SUM：多智能体LLM架构革新长篇叙事摘要](generated_articles/2025-06-02_NEXUS_SUM：多智能体LLM架构革新长篇叙事摘要.txt)
- 2025-06-02 [TH-Bench：揭秘AI文本攻防战，让人类与机器的界限更模糊](generated_articles/2025-06-02_TH-Bench：揭秘AI文本攻防战，让人类与机器的界限更模糊.txt)
- 2025-06-02 [GeoDrive：3D几何驱动的自动驾驶世界模型，实现精准动作控制](generated_articles/2025-06-02_GeoDrive：3D几何驱动的自动驾驶世界模型，实现精准动作控制.txt)
- 2025-06-02 [Gemini_2.5_Pro：AI教育领域的新星，教育专家盲测力压群雄](generated_articles/2025-06-02_Gemini_2.5_Pro：AI教育领域的新星，教育专家盲测力压群雄.txt)
- 2025-05-30 [AI互动戏剧：当LLM遇上沉浸式剧情，人人都是主角](generated_articles/2025-05-30_AI互动戏剧：当LLM遇上沉浸式剧情，人人都是主角.txt)
- 2025-05-30 [单样本熵最小化：大语言模型后训练的意外突破](generated_articles/2025-05-30_单样本熵最小化：大语言模型后训练的意外突破.txt)
- 2025-05-30 [AMOR：多目标强化学习助力物理角色自适应控制](generated_articles/2025-05-30_AMOR：多目标强化学习助力物理角色自适应控制.txt)
- 2025-05-29 [LLM_Agent不确定性量化：传统方法亟待重新评估](generated_articles/2025-05-29_LLM_Agent不确定性量化：传统方法亟待重新评估.txt)
- 2025-05-29 [揭秘大语言模型微调的“学习动力学”：理解幻觉与DPO的奥秘](generated_articles/2025-05-29_揭秘大语言模型微调的“学习动力学”：理解幻觉与DPO的奥秘.txt)
- 2025-05-29 [MaskedManipulator：AI操控人形机器人实现高精度人机交互](generated_articles/2025-05-29_MaskedManipulator：AI操控人形机器人实现高精度人机交互.txt)
- 2025-05-29 [模型“体检”：用统计学“听诊器”诊断AI部署风险](generated_articles/2025-05-29_模型“体检”：用统计学“听诊器”诊断AI部署风险.txt)
- 2025-05-28 [UniGen：多模态大模型理解与生成的新突破](generated_articles/2025-05-28_UniGen：多模态大模型理解与生成的新突破.txt)
- 2025-05-28 [Paper2Poster：AI自动生成学术海报，告别熬夜排版！](generated_articles/2025-05-28_Paper2Poster：AI自动生成学术海报，告别熬夜排版！.txt)
- 2025-05-28 [InstructPart：AI学会“庖丁解物”，助力机器人更智能](generated_articles/2025-05-28_InstructPart：AI学会“庖丁解物”，助力机器人更智能.txt)
- 2025-05-27 [GLIDER：分而治之，让AI智能体更高效地解决复杂问题](generated_articles/2025-05-27_GLIDER：分而治之，让AI智能体更高效地解决复杂问题.txt)
- 2025-05-27 [预测未来，操控现实：AI机器人策略新突破](generated_articles/2025-05-27_预测未来，操控现实：AI机器人策略新突破.txt)
- 2025-05-27 [AI考古学家诞生？HistAgent挑战历史推理极限](generated_articles/2025-05-27_AI考古学家诞生？HistAgent挑战历史推理极限.txt)
- 2025-05-27 [DexWild：让人人都能教会机器人灵巧操作](generated_articles/2025-05-27_DexWild：让人人都能教会机器人灵巧操作.txt)
- 2025-05-26 [无需输出！新型AI自评估技术揭秘：像人类一样思考](generated_articles/2025-05-26_无需输出！新型AI自评估技术揭秘：像人类一样思考.txt)
- 2025-05-24 [T2I-R1：双链思考强化图像生成，RL助力AI“画”出新境界](generated_articles/2025-05-24_T2I-R1：双链思考强化图像生成，RL助力AI“画”出新境界.txt)
- 2025-05-24 [MAC-VO：让机器人视觉更可靠的秘密武器——基于度量感知的协方差学习](generated_articles/2025-05-24_MAC-VO：让机器人视觉更可靠的秘密武器——基于度量感知的协方差学习.txt)
- 2025-05-24 [AI科学家进化：NovelSeek打造自主科研闭环，加速创新发现](generated_articles/2025-05-24_AI科学家进化：NovelSeek打造自主科研闭环，加速创新发现.txt)
- 2025-05-24 [EgoDex：苹果发布大规模第一人称操作数据集，助力机器人灵巧操作](generated_articles/2025-05-24_EgoDex：苹果发布大规模第一人称操作数据集，助力机器人灵巧操作.txt)
- 2025-05-23 [D(R,O)Grasp：机器人与物体交互的统一表示，实现跨形态灵巧抓取](generated_articles/2025-05-23_D(R,O)Grasp：机器人与物体交互的统一表示，实现跨形态灵巧抓取.txt)
- 2025-05-23 [DeCafNet：AI“分而治之”策略，让长视频理解又快又准](generated_articles/2025-05-23_DeCafNet：AI“分而治之”策略，让长视频理解又快又准.txt)
- 2025-05-23 [SELP：让大语言模型为机器人生成安全高效的任务规划](generated_articles/2025-05-23_SELP：让大语言模型为机器人生成安全高效的任务规划.txt)
- 2025-05-22 [Robo-DM：机器人大数据的高效管理之道](generated_articles/2025-05-22_Robo-DM：机器人大数据的高效管理之道.txt)
- 2025-05-22 [BountyBench：AI攻防在真实网络安全系统中的价值量化](generated_articles/2025-05-22_BountyBench：AI攻防在真实网络安全系统中的价值量化.txt)
- 2025-05-22 [AI机器人新技能：看视频学人类，轻松驾驭楼梯和椅子](generated_articles/2025-05-22_AI机器人新技能：看视频学人类，轻松驾驭楼梯和椅子.txt)
- 2025-05-21 [机器人玩转七巧板：AI新策略让组装难题迎刃而解](generated_articles/2025-05-21_机器人玩转七巧板：AI新策略让组装难题迎刃而解.txt)
- 2025-05-21 [MeanFlow：全新平均流模型，单步生成高质量图像](generated_articles/2025-05-21_MeanFlow：全新平均流模型，单步生成高质量图像.txt)
- 2025-05-21 [MemVR：让AI“再看一眼”，告别多模态大语言模型的幻觉](generated_articles/2025-05-21_MemVR：让AI“再看一眼”，告别多模态大语言模型的幻觉.txt)
- 2025-05-20 [多语种摘要生成：大语言模型能力深度评测与启示](generated_articles/2025-05-20_多语种摘要生成：大语言模型能力深度评测与启示.txt)
- 2025-05-20 [DREAM_GEN：用AI梦境解锁机器人学习的无限可能](generated_articles/2025-05-20_DREAM_GEN：用AI梦境解锁机器人学习的无限可能.txt)
- 2025-05-20 [ToolSpectrum：大型语言模型如何更懂你？个性化工具使用新基准](generated_articles/2025-05-20_ToolSpectrum：大型语言模型如何更懂你？个性化工具使用新基准.txt)
- 2025-05-19 [打破数据孤岛：无需补全对齐的多视角聚类新范式](generated_articles/2025-05-19_打破数据孤岛：无需补全对齐的多视角聚类新范式.txt)
- 2025-05-19 [LLM测试时扩展新思路：概率论视角下的提示策略再思考](generated_articles/2025-05-19_LLM测试时扩展新思路：概率论视角下的提示策略再思考.txt)
- 2025-05-16 [大型语言模型在多轮对话中迷失：可靠性危机](generated_articles/2025-05-16_大型语言模型在多轮对话中迷失：可靠性危机.txt)
- 2025-05-16 [大型语言模型代码生成难题：结构性重复及RPG解决方案](generated_articles/2025-05-16_大型语言模型代码生成难题：结构性重复及RPG解决方案.txt)
- 2025-05-16 [AI_Agent与Agentic_AI：一场关于智能体进化的深度解读](generated_articles/2025-05-16_AI_Agent与Agentic_AI：一场关于智能体进化的深度解读.txt)
- 2025-05-16 [SpikeVideoFormer：突破性SNN视频处理架构，效率媲美ANN](generated_articles/2025-05-16_SpikeVideoFormer：突破性SNN视频处理架构，效率媲美ANN.txt)
- 2025-05-16 [AI读懂肢体语言：机器人也能和你一起“吃力”地推东西了！](generated_articles/2025-05-16_AI读懂肢体语言：机器人也能和你一起“吃力”地推东西了！.txt)
- 2025-05-15 [生成式AI赋能自动驾驶：前沿进展与未来展望](generated_articles/2025-05-15_生成式AI赋能自动驾驶：前沿进展与未来展望.txt)
- 2025-05-15 [AI强化电网：深度学习助力多阶段连锁故障缓解](generated_articles/2025-05-15_AI强化电网：深度学习助力多阶段连锁故障缓解.txt)
- 2025-05-15 [Variational_VQA：提升视觉问答模型可靠性的新途径](generated_articles/2025-05-15_Variational_VQA：提升视觉问答模型可靠性的新途径.txt)
- 2025-05-15 [RFPG：强化学习新策略，让智能体在复杂环境中更稳健](generated_articles/2025-05-15_RFPG：强化学习新策略，让智能体在复杂环境中更稳健.txt)
- 2025-05-14 [AI新突破：无需梯度，用视觉引导解码生成高质量图像提示词](generated_articles/2025-05-14_AI新突破：无需梯度，用视觉引导解码生成高质量图像提示词.txt)
- 2025-05-14 [策略增强规划：大语言模型在对抗环境中的新突破](generated_articles/2025-05-14_策略增强规划：大语言模型在对抗环境中的新突破.txt)
- 2025-05-14 [UniSkill：让机器人像人一样学习，无需成对数据！](generated_articles/2025-05-14_UniSkill：让机器人像人一样学习，无需成对数据！.txt)
- 2025-05-13 [MiMo-7B：小米发布推理能力至上的大语言模型，7B参数超越32B模型](generated_articles/2025-05-13_MiMo-7B：小米发布推理能力至上的大语言模型，7B参数超越32B模型.txt)
- 2025-05-13 [揭秘大语言模型持续预训练：Scaling_Law如何预测模型性能？](generated_articles/2025-05-13_揭秘大语言模型持续预训练：Scaling_Law如何预测模型性能？.txt)
- 2025-05-13 [TREND：三方教学法助力强化学习在嘈杂偏好数据中稳健前行](generated_articles/2025-05-13_TREND：三方教学法助力强化学习在嘈杂偏好数据中稳健前行.txt)
- 2025-05-12 [CLAM：无需专家数据，让机器人从无标签视频中学会精细动作](generated_articles/2025-05-12_CLAM：无需专家数据，让机器人从无标签视频中学会精细动作.txt)
- 2025-05-12 [快手AI内容审核新突破：VLM模型KuaiMod打造类Common_Law短视频治理框架](generated_articles/2025-05-12_快手AI内容审核新突破：VLM模型KuaiMod打造类Common_Law短视频治理框架.txt)
- 2025-05-12 [让机器人去远足：人形机器人复杂地形自主行走新突破](generated_articles/2025-05-12_让机器人去远足：人形机器人复杂地形自主行走新突破.txt)
- 2025-05-11 [AI侦探出动：揪出LLM多智能体系统中的“罪魁祸首”](generated_articles/2025-05-11_AI侦探出动：揪出LLM多智能体系统中的“罪魁祸首”.txt)
- 2025-05-11 [模型融合新思路：赋予视觉模型推理能力](generated_articles/2025-05-11_模型融合新思路：赋予视觉模型推理能力.txt)
- 2025-05-11 [AI学术评审危机：引入作者反馈与评审激励机制](generated_articles/2025-05-11_AI学术评审危机：引入作者反馈与评审激励机制.txt)
- 2025-05-11 [模型融合新思路：为视觉模型注入推理能力](generated_articles/2025-05-11_模型融合新思路：为视觉模型注入推理能力.txt)
- 2025-05-11 [AI新突破：大型语言模型赋能情感肢体表达理解](generated_articles/2025-05-11_AI新突破：大型语言模型赋能情感肢体表达理解.txt)
- 2025-05-09 [AI新策略：多智能体协作学习迎来“状态建模”与“对抗探索”双重加持](generated_articles/2025-05-09_AI新策略：多智能体协作学习迎来“状态建模”与“对抗探索”双重加持.txt)
- 2025-05-09 [CUDA：让AI模型在不同场景下也能理解“概念”](generated_articles/2025-05-09_CUDA：让AI模型在不同场景下也能理解“概念”.txt)
- 2025-05-08 [视觉图提示：语义低秩分解助力AI理解图像](generated_articles/2025-05-08_视觉图提示：语义低秩分解助力AI理解图像.txt)
- 2025-05-08 [Argus：毫米波雷达加持，可穿戴设备实现人体3D建模新突破](generated_articles/2025-05-08_Argus：毫米波雷达加持，可穿戴设备实现人体3D建模新突破.txt)
- 2025-05-08 [基于弱监督学习的公平城市交通流量估计](generated_articles/2025-05-08_基于弱监督学习的公平城市交通流量估计.txt)
- 2025-05-08 [AI机器人大升级：π0.5学会收拾房间，还能举一反三！](generated_articles/2025-05-08_AI机器人大升级：π0.5学会收拾房间，还能举一反三！.txt)
- 2025-05-08 [ABKD：用α-β散度巧妙平衡知识蒸馏中的难题](generated_articles/2025-05-08_ABKD：用α-β散度巧妙平衡知识蒸馏中的难题.txt)
- 2025-05-08 [厉害了！AI只看卫星图，就能算出哪里人多？还能预测战争走向！](generated_articles/2025-05-08_厉害了！AI只看卫星图，就能算出哪里人多？还能预测战争走向！.txt)
- 2025-05-08 [视觉图提示：用语义低秩分解提升AI图像识别能力](generated_articles/2025-05-08_视觉图提示：用语义低秩分解提升AI图像识别能力.txt)
- 2025-05-08 [AI界“华山论剑”！多模态大模型迎来首次能力分级，谁能问鼎AI之巅？](generated_articles/2025-05-08_AI界“华山论剑”！多模态大模型迎来首次能力分级，谁能问鼎AI之巅？.txt)
- 2025-05-08 [多模态通用智能新阶梯：General-Level与General-Bench](generated_articles/2025-05-08_多模态通用智能新阶梯：General-Level与General-Bench.txt)

# Daily-ArXiv

网站：https://daily-ar-xiv.vercel.app

一个用于自动获取、解读最新ArXiv计算机视觉论文，并生成科普文章及相关图片的Python项目。

## 主要功能

*   **自动获取ArXiv论文**：从ArXiv网站抓取最新的计算机视觉领域论文信息。
*   **PDF处理**：下载论文PDF文件，并从中提取文本内容。
*   **AI驱动的内容生成**：利用Gemini API将专业论文解读为通俗易懂、风格生动的科普文章。
*   **图片提取**：
    *   生成论文首页的截图。
    *   从论文中提取并保存相关的插图。
*   **自动化与手动模式**：提供每日自动处理和手动指定论文处理两种模式。
*   **内容存储**：将生成的科普文章（TXT格式）和提取的图片保存在结构化的目录中。

## 包含的脚本

1.  **`daily.py`**：
    *   **用途**：每日自动运行，从ArXiv的计算机视觉板块（cs.CV/recent）获取指定数量的最新论文。
    *   **处理流程**：自动下载PDF，提取文本，调用Gemini API生成"严谨但生动"风格的科普文章，提取首页截图和插图，并将所有内容按日期和标题保存。
    *   **特点**：无需手动输入，适合每日自动更新内容。

2.  **`arxiv.py`**：
    *   **用途**：手动模式，用户通过命令行输入指定的ArXiv论文PDF链接。
    *   **处理流程**：下载指定PDF，提取完整文本，调用Gemini API生成"严谨但生动"风格（篇幅稍长，约800-900字）的科普文章，并将生成的TXT文件按日期和标题保存。 *（注意：当前`arxiv.py`的图片提取功能可能需要根据`daily.py`的实现进行同步更新）*
    *   **特点**：适合对特定论文进行精细化、深度解读。

## 技术栈与依赖

*   **Python 3.x**
*   **主要Python库**：
    *   `requests`：用于HTTP请求，获取ArXiv页面和下载PDF。
    *   `BeautifulSoup4`：用于解析HTML，从ArXiv页面提取论文信息。
    *   `PyPDF2`：用于基础的PDF文本提取。
    *   `PyMuPDF` (fitz)：用于从PDF中提取内嵌的图片对象。
    *   `pdf2image`：用于将PDF页面转换为图片（生成首页截图）。
*   **外部工具**：
    *   `Poppler`：`pdf2image`的依赖，用于PDF渲染。**必须正确安装并配置到系统PATH。**
*   **API**：
    *   Google Gemini API：用于生成论文解读文章。

## 安装与配置

1.  **克隆项目**（如果您是从版本控制获取）：
    ```bash
    # git clone <repository_url>
    # cd Daily-ArXiv
    ```

2.  **创建并激活Python虚拟环境**（推荐）：
    在项目根目录下执行：
    ```bash
    python3 -m venv .venv  # 创建名为 .venv 的虚拟环境
    source .venv/bin/activate # 激活 (macOS/Linux)
    # .env\Scripts\activate  # 激活 (Windows)
    ```

3.  **安装Python依赖**：
    在激活的虚拟环境中运行：
    ```bash
    pip install requests beautifulsoup4 PyPDF2 PyMuPDF pdf2image
    ```

4.  **安装Poppler**：
    *   **macOS**: `brew install poppler`
    *   **Linux (Debian/Ubuntu)**: `sudo apt-get install poppler-utils`
    *   **Windows**: 
        1.  从可信赖的源（如 [Poppler for Windows on GitHub](https://github.com/oschwartz10612/poppler-windows/releases/)) 下载最新的Poppler二进制文件 (通常是一个.zip或.7z包)。
        2.  解压缩下载的文件到一个稳定的位置（例如 `C:\Program Files\poppler-xxxx`）。
        3.  将解压后Poppler目录下的 `bin` 子目录（例如 `C:\Program Files\poppler-xxxx\bin`）添加到系统的PATH环境变量中。
        4.  重启命令行/终端或IDE以使PATH更改生效。

5.  **配置API密钥**：
    *   打开 `daily.py` 和 `arxiv.py` 文件。
    *   找到 `API_KEY = 'YOUR_GEMINI_API_KEY'` 这一行（或类似）。
    *   将 `'YOUR_GEMINI_API_KEY'` 替换为您自己的有效Google Gemini API密钥。
    *   **安全提示**：直接在代码中硬编码API密钥存在风险。建议使用环境变量等更安全的方式管理密钥，例如：
        ```python
        # API_KEY = os.environ.get('GEMINI_API_KEY')
        ```
        然后在您的环境中设置 `GEMINI_API_KEY` 环境变量。

## 使用方法

确保您的Python虚拟环境已激活。

*   **运行 `daily.py` (自动每日模式)**：
    ```bash
    python daily.py
    ```
    脚本将自动从ArXiv获取最新的 `NUM_PAPERS_TO_PROCESS` (默认为5) 篇cs.CV论文，并进行处理。

*   **运行 `arxiv.py` (手动模式)**：
    ```bash
    python arxiv.py
    ```
    脚本会提示您输入一个ArXiv论文的PDF链接。

## 输出

*   生成的科普文章（`.txt` 文件）和相关图片将保存在项目根目录下的 `generated_articles/` 文件夹中。
*   文本文件名格式：`YYYY-MM-DD_文章标题.txt`。
*   图片将保存在对应文章的子目录中，格式为：`generated_articles/YYYY-MM-DD_文章标题_images/`。
    *   首页截图：`文章标题_first_page.png`
    *   插图：`文章标题_illustration_X.ext` (X为序号，ext为图片原始扩展名)

## 注意事项

*   **ArXiv页面结构**：`daily.py` 的网页抓取逻辑依赖于ArXiv页面的当前HTML结构。如果ArXiv网站更新其结构，可能需要调整`fetch_arxiv_papers`函数中的解析代码。
*   **动态加载**：如果ArXiv的 `recent` 页面严重依赖JavaScript动态加载大量内容，`requests` 可能无法获取所有条目。当前脚本的 `fetch_arxiv_papers` 包含调试日志，若发现获取条目不足，可能需要考虑使用Selenium等浏览器自动化工具代替`requests`。
*   **PDF质量**：PDF文本提取和图片提取的效果很大程度上取决于源PDF的质量和结构。扫描版PDF、加密PDF或包含复杂矢量图形的PDF可能无法完美处理。
*   **API使用**：请注意您使用的Gemini API的调用频率限制和配额。
*   **Poppler依赖**：图片提取（尤其是首页截图）强依赖于Poppler的正确安装和配置。

## 未来可能的改进

*   集成Selenium或Playwright以更稳定地处理动态加载的网页。
*   为图片提取实现更智能的筛选逻辑（例如，基于图片内容、上下文等）。
*   提供配置选项，允许用户通过配置文件或命令行参数修改API密钥、处理论文数量等。
*   增加对已处理论文的记录，避免重复处理。
*   完善错误处理和日志记录机制。

## 前端界面 (HTML)

本项目还包含一个基本的前端HTML界面 (`index.html`, `style.css`, `script.js`)，允许用户通过浏览器直接与论文解读功能交互。

**前端功能：**

*   输入ArXiv论文的PDF链接。
*   在浏览器端使用 `pdf.js` 提取PDF文本。
*   **直接在前端调用Google Gemini API** 生成论文解读。
*   显示生成的解读文章标题和内容。
*   提供原文PDF下载按钮。
*   提供解读文本的`.txt`文件下载按钮。

**运行前端界面：**

1.  **配置API密钥**：打开 `script.js` 文件，将文件顶部的 `YOUR_GEMINI_API_KEY` 替换为您真实的Google Gemini API密钥。
    ```javascript
    const GEMINI_API_KEY = 'YOUR_GEMINI_API_KEY'; 
    ```
2.  **配置GitHub链接**：打开 `index.html` 文件，修改文件头部的GitHub项目链接为您自己的仓库地址。
3.  **本地测试**：
    *   由于浏览器安全策略 (CORS) 和 `pdf.js` worker的加载，直接通过 `file:///` 协议打开 `index.html` 可能无法正常工作。
    *   建议通过一个本地HTTP服务器来运行。如果您安装了Python，可以在项目根目录下运行：
        ```bash
        python -m http.server
        ```
        然后在浏览器中访问 `http://localhost:8000` (或Python提示的其他端口)。
4.  **Vercel部署**：您可以将这三个文件 (`index.html`, `style.css`, `script.js`) 直接部署到Vercel。但请再次注意下面的安全警告。
